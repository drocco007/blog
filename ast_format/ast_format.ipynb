{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Unicode `.format` Nanny with Python's AST\n",
    "\n",
    "##### Detecting problematic `.format` calls quickly and painlessly using Python's powerful `ast` module.\n",
    "\n",
    "The issue: where I work, we are still a Python 2 shop owing to technical debt and legacy dependencies. Since Python 2's default string type is a byte sequence, painful encoding-related problems surface in our applications from time to time. A fairly typical example runs something like this: a developer writes some code to format data into a string, using the convenient and powerful `.format` method supported by all string objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_format(some_data):\n",
    "    return 'Hello, {}!'.format(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the course of our exhaustive testing, we prove that this function is correct over a wide range of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print pretty_format('world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code ships. Months pass without incident, our `pretty_format` routine prettily formatting every bit of data thrown its way. Lulled into complacency through enjoyment of our apparent success, we move on to other tasks. One day, everything comes to a screeching halt as, completely unprepared, we receive one of the most dreaded error messages in all of software development:\n",
    "\n",
    "    UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 8: ordinal not in range(128)\n",
    "\n",
    "What happened? Why did code that worked flawlessly for months suddenly detonate, without warning, without mercy?\n",
    "\n",
    "Much of the data that flows through this format template and others like it is simple ASCII-valued information: dates, addresses, phone numbers, and the like. Having used Python 2 for many years, we are habituated to spell strings, including our template formatting strings, using the simple single quote\n",
    "\n",
    "```python\n",
    "'a typical string'\n",
    "```\n",
    "\n",
    "What happens, though, when our user data contains an accented character or other non-ASCII symbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xc9' in position 8: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3d955b7228e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfull_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mu'Ariadne Éowyn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mpretty_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-51c87778ff71>\u001b[0m in \u001b[0;36mpretty_format\u001b[1;34m(some_data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpretty_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msome_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Hello, {}!'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msome_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xc9' in position 8: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "full_name = u'Ariadne Éowyn'\n",
    "print pretty_format(full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom! Python detects the mismatch between the binary string template object and the Unicode data containing some multi-byte characters that simply cannot be represented directly in the target format, ASCII. In other words, Python is refusing to guess what we want: do we prefer a binary expansion, and, if so, in what encoding? Should the accent characters simply be dropped? Do we want unexpected symbols to be translated into ASCII error characters? Python has no way of knowing which of these options is appropriate to the present situation, so it takes the only reasonable course and raises an exception.\n",
    "\n",
    "Many Unicode issues can be quite challenging to reconcile, but this case is rather simple: if the format string is specified in Unicode format — rather than as a plain binary string — this entire class of problem would be avoided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Ariadne Éowyn!\n"
     ]
    }
   ],
   "source": [
    "def pretty_format(some_data):\n",
    "    # Unicode object template prepares this routine to handle non-ASCII symbols\n",
    "    return u'Hello, {}!'.format(some_data)\n",
    "\n",
    "print pretty_format(full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we know where the problematic calls to `.format` are lurking in our code base without waiting for the next error to occur? Is there a way we could find these calls proactively, eliminating them from the system before they wreak havoc on our application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief diversion: now you have two problems\n",
    "\n",
    "When I first mentioned the idea of automatically detecting problematic `.format` calls to a coworker, he immediately quipped back “have fun writing *that* regex!” Before we look at a more powerful and reliable alternative, let's take a moment to examine his intuition and understand why we might not want to use regular expressions for this task.\n",
    "\n",
    "At first glance, regular expressions seem reasonably well suited to this job: what we're looking for are substrings of a given string — that is, parts of a Python source file — containing a certain pattern. Indeed it is fairly easy to construct a first cut at a regular expression for this problem. Here is mine, including a bunch of explanatory comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# a first draft regular expression for detecting \n",
    "# problematic .format calls\n",
    "pattern = re.compile(r'''\n",
    "    (?x)        # turn on verbose regex mode\n",
    "    \n",
    "    (?<!u)      # ignore matches that start with a u\n",
    "    \n",
    "    '           # match ', followed by \n",
    "    [^']*       # any number of non-' characters,\n",
    "    '           # followed by '\n",
    "    \n",
    "    \\.format    # only if the string is followed by a\n",
    "                # call to .format\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to work well for some simple cases: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_problem(s):\n",
    "    return bool(pattern.search(s))\n",
    "\n",
    "print is_problem(\"message = 'Hello, world!'\")\n",
    "print is_problem(\"message = 'Hello, {}!'.format\")\n",
    "print is_problem(\"message = u'Hello, {}!'.format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if the code we're examining uses double quoted strings? Or multiline strings? Does the regular expression we've concocted handle continuation lines correctly? Backslash escapes? Comments?\n",
    "\n",
    "    'another {}string' \\\n",
    "        .format\n",
    "        \n",
    "    \"now you're just\" \\\n",
    "    'bein\\' {}annoyin\\''.format(u'seriously ')\n",
    "    \n",
    "    # 'ignore me'.format\n",
    "\n",
    "What happens if we use the Python parser's string combination feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a false positive\n",
    "is_problem(\"\"\"\n",
    "    u'this ' 'and this are the same string{}'.format\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you get in your time machine and import Unicode literals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another false positive\n",
    "is_problem(\"\"\"\n",
    "    from __future__ import unicode_literals\n",
    "    \n",
    "    'Unicode masquerading as {}'.format\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be effective, our source examination tool needs to handle all these cases and more so that team members will trust the feedback they are receiving: we don't want to create [alarm fatigue](https://en.wikipedia.org/wiki/Alarm_fatigue) by producing false or spurious warnings. On the other hand, there are many edge cases and difficult combinations that will require a complicated parser solution to handle correctly.\n",
    "\n",
    "Notice, though, that Python's own parser already deals with all of these difficulties when interpreting our source code! Since the Python language and community emphasize openness and introspection, it will probably come as no surprise that this machinery is exposed and available to Python programs. Using the `ast` module, we can transform arbitrary Python source into a tree representation, with all of the aforementioned parsing complexities already handled for us. Our task then becomes much simpler: we merely need to inspect this tree and report any instances of calls to `.format` that are made on byte strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's an AST?\n",
    "\n",
    "An abstract syntax tree (AST) is an object representation of the syntactic parts of a program and of the relationship between those parts. If we have some program fragment,\n",
    "\n",
    "```python\n",
    "for little_one in ['Asher', 'Ansel', 'Ariadne', 'Andromeda']:\n",
    "    name_complexity = len(little_one)\n",
    "    print name_complexity\n",
    "```\n",
    "\n",
    "we can observe that there is a lot going on in even a relatively simple construct like this one:\n",
    "\n",
    "* the entire construct is a logical unit with respect to the other statements that may surround it. For example, moving this statement around will not change its internal semantics (although moving it may still affect the semantics of the program around it)\n",
    "* the statement itself consists of 3 components: the *iterable* that supplies the values for the loop, the assignment *target*, and the loop *body*, which is in turn composed of multiple statements\n",
    "* each of the parts have a specific relationship to the others that is communicated by the source code. This relationship forms part of the semantic structure of the statement: if we were to move the `print` call back 4 spaces, we would alter the *relationship* of the parts to each other and therefore the semantics of the entire statement:\n",
    "\n",
    "```python\n",
    "for little_one in ['Asher', 'Ansel', 'Ariadne', 'Andromeda']:\n",
    "    name_complexity = len(little_one)\n",
    "print name_complexity\n",
    "```\n",
    "\n",
    "An AST captures these nuances in object form. In an AST representation, nodes model individual constructs in the program, drawn from the set of all available constructs defined by the language. In Python, for example, we have node types representing `Module`, `For`, `Name`, and `Str`. Each node captures both the type of construct being represented and the details of a particular instance: the `Name` class represents all possible variable usages, while a particular instance of `Name` in an AST will include the specific name used at a given point in a program and whether that name is being read from or written to.\n",
    "\n",
    "Let's take a look at the AST representation of this for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[For(target=Name(id='little_one', ctx=Store()), iter=List(elts=[Str(s='Asher'), …\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "tree = ast.parse(\"\"\"\n",
    "\n",
    "for little_one in ['Asher', 'Ansel', 'Ariadne', 'Andromeda']:\n",
    "    name_complexity = len(little_one)\n",
    "    print name_complexity\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print ast.dump(tree)[:92] + u'…'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we parse the source text into a tree representation, then ask the `ast` module to dump that tree structure back out as text. Since the output of `ast.dump` can be somewhat difficult to read, I've indented this particular trace by hand to reveal the relationship structure of the tree:\n",
    "\n",
    "    Module(body=[\n",
    "      For(\n",
    "        target=Name(id='little_one', ctx=Store()), \n",
    "        iter=List(\n",
    "          elts=[Str(s='Asher'), Str(s='Ansel'), \n",
    "                Str(s='Ariadne'), Str(s='Andromeda')], \n",
    "          ctx=Load()), \n",
    "        body=[\n",
    "          Assign(\n",
    "            targets=[Name(id='name_complexity', ctx=Store())], \n",
    "            value=Call(\n",
    "              func=Name(id='len', ctx=Load()), \n",
    "              args=[Name(id='little_one', ctx=Load())], \n",
    "              keywords=[], \n",
    "              starargs=None, \n",
    "              kwargs=None)), \n",
    "          Print(\n",
    "            dest=None, \n",
    "            values=[Name(id='name_complexity', ctx=Load())], \n",
    "            nl=True)], \n",
    "        orelse=[]\n",
    "      )\n",
    "    ])\n",
    "\n",
    "The `Module` object is the outermost container for our code. It corresponds to a `.py` file and contains a single attribute, `body`, that contains the list of statements — imports, assignments, function and class definitions, etc. — that make up the module. For this simple example, the module body contains one element: our for loop.\n",
    "\n",
    "With a little squinting, you can see the two body statements contained within the for loop attached to the `For` node's `body` attribute: `Assign` and `Print`. This brings the total number of direct children of the `For` node to four: a `List` node as its iterable, a `Name` node as its target, and the `Assign` and `Print` nodes making up its body. The `List`, `Assign`, and `Print` nodes each have their own children representing the string literals that make up the list, both sides of the assignment statement, and the values we wish to print. \n",
    "\n",
    "Given this general introduction to Python's AST, here are two examples illuminating what our `.format` nanny will be looking for; first is a case we want to alert the user about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Expr(value=Attribute(value=Str(s='a {}string'), attr='format', ctx=Load()))])\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.dump(ast.parse(\"'a {}string'.format\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "followed by an acceptable spelling that should produce no warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Module(body=[Expr(value=Attribute(value=Str(s=u'a {}string'), attr='format', ctx=Load()))])\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.dump(ast.parse(\"u'a {}string'.format\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating this into a textual description lets us refine the problem statement we formulated earlier: we are looking for `Attribute` nodes with an `attr` of `'format'` and whose `value` is a `Str` node. If that `Str` node's `s` attribute starts with a `'` and not a `u`, we have found a problematic spelling and should warn the user.\n",
    "\n",
    "Stop and ponder this for a moment. Notice how we've gone from a definite but ambiguous notion of what we wanted to a simple, precise, and implementable description that leverages the transformation of source text into a tree representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visiting `.format`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `ast` module provides a tree traversal framework for working with ASTs that is based on the Visitor pattern. For each node type, a custom traverser defines a method corresponding to that type that will be invoked whenever the traversal encounters such a node. For example, here's the basic template for working with `Attribute` nodes:\n",
    "\n",
    "```python\n",
    "class MyVisitor(ast.NodeVisitor):\n",
    "    def visit_Attribute(self, node):\n",
    "        # do something with Attribute nodes\n",
    "```\n",
    "\n",
    "\n",
    "Let's do some exploratory coding. We've already seen the basic structure of the `Attribute` nodes we're looking for, but what else is available to us as we're traversing an AST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ast.parse(\"\"\"\n",
    "\n",
    "'Hello, {}!'.format('world')\n",
    "\n",
    "pi = math.pi\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col_offset': 0, 'ctx': <_ast.Load object at 0x7fc1e7f17a10>, 'attr': 'format', 'value': <_ast.Str object at 0x7fc1e03dba50>, 'lineno': 3}\n",
      "{'s': 'Hello, {}!', 'lineno': 3, 'col_offset': 0}\n",
      "\n",
      "{'col_offset': 5, 'ctx': <_ast.Load object at 0x7fc1e7f17a10>, 'attr': 'pi', 'value': <_ast.Name object at 0x7fc1e03dbc10>, 'lineno': 5}\n",
      "{'ctx': <_ast.Load object at 0x7fc1e7f17a10>, 'id': 'math', 'col_offset': 5, 'lineno': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttributeInspector(ast.NodeVisitor):\n",
    "    def visit_Attribute(self, node):\n",
    "        print node.__dict__\n",
    "        print node.value.__dict__\n",
    "        print\n",
    "\n",
    "AttributeInspector().visit(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little class simply prints the instance dictionaries for each `Attribute` node in the tree along with that of its `value` attribute. I often use this trick (`print obj.__dict__`) when exploring a problem to help me understand the attributes and capabilities of unknown objects. For this particular problem, our inspector has revealed that each node type has a different set of attributes defined on it and given us clues to help us advance to a solution.\n",
    "\n",
    "As expected, there are two `Attribute` nodes in our little example program, corresponding to the `.format` and `.pi` references in the source. We saw earlier that we are specifically looking for nodes with an `attr` of `'format'`, and our little test class revealed another bit of useful data: the line number on which the attribute access appears in the source, which will be useful information to provide back to the user.\n",
    "\n",
    "Our tiny Visitor implementation has already solved the first part of our problem: finding `Attribute` nodes in the source. All that remains is to filter down to `.format` nodes and check the value attribute of each. Here is the rest of the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FormatVisitor(ast.NodeVisitor):\n",
    "    def visit_Attribute(self, node):\n",
    "        if node.attr == 'format':\n",
    "            _str = repr(node.value.s)\n",
    "\n",
    "            if _str[0] != 'u':\n",
    "                print u'{}: {}'.format(node.lineno, _str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With just a handful of lines of Python, we have created a program that meets the goals we set out above. This solution harnesses the full power of Python's exposed parser machinery, which allows our code to express a very high level solution with a minimum of syntactic overhead. Run on our example above, it points out that line 3 of the source contains a problematic spelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 'Hello, {}!'\n"
     ]
    }
   ],
   "source": [
    "FormatVisitor().visit(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while source with an acceptable spelling yields no warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = ast.parse(\"\"\"u'Hello, {}!'.format('world')\"\"\")\n",
    "FormatVisitor().visit(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example that demonstrates some of our tricky cases from earlier, including a split string, continuation line, and even a parenthesized expression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 'Hello, {}!'\n"
     ]
    }
   ],
   "source": [
    "source = \"\"\"\n",
    "\n",
    "('Hello, '\n",
    "    '{}!') \\\n",
    ".format('world')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tree = ast.parse(source)\n",
    "FormatVisitor().visit(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same source but with corrected strings eliminates the warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = source.replace(\"('\", \"(u'\")\n",
    "tree = ast.parse(source)\n",
    "FormatVisitor().visit(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the `__future__` import case is handled correctly with no extra effort on our part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = ast.parse(\"\"\"\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "'Hello, {}!'.format('world')\n",
    "\n",
    "\"\"\")\n",
    "FormatVisitor().visit(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Looking back, looking ahead\n",
    "\n",
    "Thanks for joining me in an exploration of this lesser-used corner of the Python standard library. We now use a Git commit hook based on these ideas to help prevent these sorts of encoding problems before they even make it into the source tree. This was a fun exploration with a pragmatic result, and I hope that you have enjoyed exploring with me and learned something along the way!\n",
    "\n",
    "If you'd like to learn more, here are a few resources to continue your exploration:\n",
    "\n",
    "* [Green Tree Snakes](https://greentreesnakes.readthedocs.org/en/latest/) is Thomas Kluyver's introduction to the AST, billed as “the missing Python AST docs”\n",
    "* The [`ast` module documentation](https://docs.python.org/2/library/ast.html) contains a grammar specification and module reference\n",
    "* Andreas Dewes presented [a static analysis tool](https://us.pycon.org/2015/schedule/presentation/341/) at PyCon 2015 based on the AST\n",
    "* [Hy](http://docs.hylang.org/en/latest/) implements a Lisp interpreter in Python and makes extensive use of the AST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
